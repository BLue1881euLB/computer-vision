{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Transform\n",
    "* https://paper.dropbox.com/doc/Hough-Transform-KGkfnjuxH7hhHysOwuSFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "p = os.path.join(os.path.dirname('__file__'), '..')\n",
    "sys.path.append(p)\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "json_fpath = os.path.join(DATA_DIR, 'volleyball_frame_00665.json')\n",
    "img_fpath = os.path.join(DATA_DIR, 'volleyball_frame_00665.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(arr, fs=(10,10), cmap='gray', title=None):\n",
    "    plt.figure(figsize=fs)\n",
    "    plt.imshow(arr, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def load_img(fpath):\n",
    "    return plt.imread(fpath)\n",
    "\n",
    "def load_cv2_img(fpath, w=None, h=None, colorspace=None):\n",
    "    img = cv2.imread(img_fpath)\n",
    "    if colorspace is not None:\n",
    "        img = cv2.cvtColor(img, colorspace)\n",
    "    if None not in [w,h]:\n",
    "        img = cv2.resize(img, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "def make_boxes(meta):\n",
    "    boxes = {}\n",
    "    for idx,row in meta.iterrows():\n",
    "        box = json.loads(row.to_json())\n",
    "        fname = row['filename']\n",
    "        if fname in boxes:\n",
    "            boxes[fname].append(box)\n",
    "        else:\n",
    "            boxes[fname] = [box]\n",
    "    return boxes\n",
    "\n",
    "def threshold(img, color, thresh):\n",
    "    \"\"\"\n",
    "    color = [b, g, r] or [r,b,g] or [h,s,v]\n",
    "    thresh = margin allowed around color\n",
    "    \"\"\"\n",
    "    min_color = np.array([color[0]-thresh, color[1]-thresh, color[2]-thresh])\n",
    "    max_color = np.array([color[0]+thresh, color[1]+thresh, color[2]+thresh])\n",
    "    min_color[min_color < 0] = 0\n",
    "    max_color[max_color > 255] = 255\n",
    "    print(\"Min\", min_color)\n",
    "    print(\"Max\", max_color)\n",
    "    \n",
    "    mask = cv2.inRange(img, min_color, max_color)\n",
    "    result = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return mask, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erosion Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB\n",
    "img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "plot_img(img, fs=(14,14), title=\"Original\")\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "erosion = cv2.erode(img, kernel,iterations = 1)\n",
    "plot_img(erosion, fs=(14,14), title=\"Erosion\")\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (4,4))\n",
    "dilation = cv2.dilate(img, kernel,iterations = 2)\n",
    "plot_img(dilation, fs=(14,14), title=\"Dilation\")\n",
    "\n",
    "img = cv2.dilate(erosion, kernel, iterations = 2)\n",
    "plot_img(img, fs=(14,14), title=\"Erosion + Dilation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, ksize=(5,5), sigmaX=3)\n",
    "plot_img(gray, fs=(14,14), title=\"Grayscale\")\n",
    "\n",
    "# use Canny edge detector to find edges in the image.  The thresholds determine how\n",
    "# weak or strong an edge will be detected.  These can be tweaked.\n",
    "lower_threshold = 25\n",
    "upper_threshold = 25\n",
    "edges = cv2.Canny(gray, lower_threshold, upper_threshold)\n",
    "plot_img(edges, fs=(14,14))\n",
    "\n",
    "# Mask top of image\n",
    "edges[:425,:] = 0\n",
    "edges[700:,:] = 0\n",
    "edges[:,1150:] = 0\n",
    "plot_img(edges, fs=(14,14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html\n",
    "* https://docs.opencv.org/3.3.1/d9/db0/tutorial_hough_lines.html\n",
    "* http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm\n",
    "* Polar coords = (rho, theta)\n",
    "* rho = distance/length of normal\n",
    "* normal = perpendicular line (along target line) that intersects origin\n",
    "* theta = angle created by intersection with normal\n",
    "* Returns lines in parametric (polar coordinates) form (p, theta)\n",
    "    * p = x cos(theta) + y sin(theta)\n",
    "    * p = perpendicular distance from origin (0,0) - top left corner\n",
    "    * theta = angle formed by p and horizontal axis (counter clockwise) (radians)\n",
    "    * r is measured in pixels and 0 is measured in radians.\n",
    "![Houghlines](https://docs.opencv.org/3.0-beta/_images/houghlines1.svg)\n",
    "![hough](http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Hough_transform_diagram.png)\n",
    "\n",
    "* https://www.geeksforgeeks.org/line-detection-python-opencv-houghline-method/\n",
    "* Applications of Hough transform:\n",
    "\n",
    "    * It is used to isolate features of a particular shape within an image.\n",
    "    * Tolerant of gaps in feature boundary descriptions and is relatively unaffected by noise.\n",
    "    * Used extensively in barcode scanning, verification and recognition\n",
    "* Steps\n",
    "    * First parameter, Input image should be a binary image, so apply threshold edge detection before finding applying hough transform.\n",
    "    * Second and third parameters are r and θ(theta) accuracies respectively.\n",
    "    * Fourth argument is the threshold, which means minimum vote it should get for it to be considered as a line.\n",
    "    * Remember, number of votes depend upon number of points on the line. So it represents the minimum length of line that should be detected.\n",
    "   \n",
    "* ρ = x cos θ + y sin θ\n",
    "\n",
    "* where:\n",
    "    * ρ (rho) = distance from origin to the line. [-max_dist to max_dist].\n",
    "          max_dist is the diagonal length of the image.  \n",
    "    * θ = angle from origin to the line. [-90° to 90°]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Higher threshold means a line needs to be stronger to be detected\n",
    "thresh = 150\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, thresh)\n",
    "img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# convert polor coordinates to x,y pixel coordinates\n",
    "# origin (0,0) is top left in numpy/cv2\n",
    "# p = distance from origin (perpendicular to hough line)\n",
    "# theta = angle in radians formed by perpendicular line\n",
    "coords = []\n",
    "for line in lines:\n",
    "    for rho, theta in line:\n",
    "        degrees = theta * (180/math.pi)\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * -b)\n",
    "        y1 = int(y0 + 1000 * a)\n",
    "        x2 = int(x0 - 1000 * -b)\n",
    "        y2 = int(y0 - 1000 * a)\n",
    "\n",
    "        if degrees > 145:\n",
    "            orient = 'right_vertical'\n",
    "        elif degrees < 45:\n",
    "            orient = 'left_vertical'\n",
    "        elif degrees > 85 and degrees < 95:\n",
    "            orient = 'horizontal'\n",
    "        else:\n",
    "            orient = 'other'\n",
    "            \n",
    "        coords.append([x1,y1,x2,y2,rho,theta,degrees,orient])\n",
    "\n",
    "        img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "        cv2.line(img, pt1=(x1, y1), pt2=(x2, y2), color=(0, 0, 255), thickness=3)\n",
    "        plot_img(img, fs=(18,18), title=coords[-1])\n",
    "\n",
    "# write the image to disk\n",
    "plot_img(img, fs=(18,18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Hough Lines Probabalistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hough Transform - Lines\n",
    "\n",
    "x_delta = 100\n",
    "y_delta = 100\n",
    "min_line_length = 400\n",
    "max_line_gap = 1500\n",
    "thresh = 100\n",
    "#minLineLength - Minimum length of line\n",
    "#maxLineGap - Maximum allowed gap between line segments to treat them as single line.\n",
    "lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180,\n",
    "                        threshold=thresh, maxLineGap=max_line_gap, \n",
    "                        minLineLength=min_line_length)\n",
    "line_coords = []\n",
    "\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    slope = (y2-y1) / (x2-x1)\n",
    "    print(x1,y1,x2,y2,slope)\n",
    "    if abs(x2 - x1) < x_delta:\n",
    "        orient = 'vertical'\n",
    "    elif abs(y2 - y1) < y_delta:\n",
    "        orient = 'horizontal'\n",
    "    else:\n",
    "        orient = 'other' #None\n",
    "    coords = [x1,y1,x2,y2,slope,orient]\n",
    "    line_coords.append(coords)\n",
    "    img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "    cv2.line(img, pt1=(x1, y1), pt2=(x2, y2), color=(0, 0, 255), thickness=3)\n",
    "    plot_img(img, fs=(18,18), title=coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up Hough Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://campushippo.com/lessons/detect-highway-lane-lines-with-opencv-and-python-21438a3e2\n",
    "* How to clean up the lines, extend them, and average nearby lines?\n",
    "* https://stackoverflow.com/questions/44449871/fine-tuning-hough-line-function-parameters-opencv\n",
    "* Since the lines are mostly vertical and horizontal, you can easily split the lines based on their position. If the two y-coordinates of one line are near each other, then the line is mostly horizontal. If the two x-coordinates are near each other, then the line is mostly vertical. So you can segment your lines into vertical lines and horizontal lines that way.\n",
    "* https://alyssaq.github.io/2014/understanding-hough-transform/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Horizontal / Vertical Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "r = negative when base of normal is above the top of image (negative y value)\n",
    "y1,y2 = negative when base of normal is above top of image\n",
    "theta = between 0 and 90 when the base of the normal is inside the image\n",
    "theta > 90 when base of normal is outside the imag\n",
    "\n",
    "Horizontal lines\n",
    "   * Angles close to 90\n",
    "   \n",
    "Vertical lines\n",
    "    * Angles close to 180/0\n",
    "    \n",
    "A volleyball court viewed straight on should have\n",
    "    * 2 horizontal lines\n",
    "    * 1 vertical line with angle close to 0\n",
    "    * 1 vertical line with angle close to 180\n",
    "    \n",
    "Taking a look at the image, we can set some sensible defaults\n",
    "\n",
    "vertical_left = angle < 45 degres\n",
    "vertical_right = angle > 145 degrees\n",
    "horizonal lines = angle between 85 and 95\n",
    "\"\"\"\n",
    "\n",
    "for coord in coords:\n",
    "    if coord[-2] > 145:\n",
    "        print('right vertical')\n",
    "    elif coord[-2] < 45:\n",
    "        print('left vertical')\n",
    "    elif coord[-2] > 85 and coord[-2] < 95:\n",
    "        print('horizontal')\n",
    "    else:\n",
    "        print('other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending Hough Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "height,width,c = img.shape\n",
    "new_coords = []\n",
    "for coord in coords:\n",
    "    x1,y1,x2,y2 = coord[:4]\n",
    "    slope = (y2-y1) / (x2-x1)\n",
    "    #y = mx + b\n",
    "    b = y1 - slope * x1\n",
    "    # x intercepts\n",
    "    x1_int = int(-b / slope) # -b/m = 0 = mx + b), x when y == 0\n",
    "    x2_int = int((height - b) / slope) #x when y == height\n",
    "    # y intercepts\n",
    "    y1_int = int(b) #y when x == 0\n",
    "    y2_int = int(slope * width + b) #y when x == width\n",
    "    details = {\n",
    "        'x1':x1,\n",
    "        'y1':y1,\n",
    "        'x2':x2,\n",
    "        'y2':y2,\n",
    "        'x1_intercept': x1_int,\n",
    "        'y1_intercept': y1_int,\n",
    "        'x2_intercept': x2_int,\n",
    "        'y2_intercept': y2_int,\n",
    "        'slope': slope,\n",
    "        'b': b,\n",
    "        'orient': coord[-1]\n",
    "    }\n",
    "    new_coords.append(details)\n",
    "    img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "    if details['orient'] == 'horizontal':\n",
    "        cv2.line(img, pt1=(0, y1_int), pt2=(width, y2_int), \n",
    "                 color=(0, 0, 255), thickness=3)\n",
    "    else:\n",
    "        cv2.line(img, pt1=(x1_int, 0), pt2=(x2_int, height), \n",
    "             color=(0, 0, 255), thickness=3)\n",
    "    plot_img(img, fs=(18,18), title=details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Intersection of Lines\n",
    "\n",
    "* Cross Product of two vectors gives the intersection\n",
    "* Steps:\n",
    "    * Given two points, find the line\n",
    "    * Find the slope\n",
    "    * Find the b intercept\n",
    "    * Convert to standard form (Ax + By + C = 0)\n",
    "    * Convert to vector form ([A B C])\n",
    "    * Compute the cross product\n",
    "* Cross product\n",
    "    * https://paper.dropbox.com/doc/Vectors-ehJskFyt7xGIdePpamfhu \n",
    "    * https://www.symbolab.com/solver/vector-cross-product-calculator\n",
    "* https://stackoverflow.com/questions/44449871/fine-tuning-hough-line-function-parameters-opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection w Cross Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_from_points(x1,y1,x2,y2):\n",
    "    m = (y2-y1) / (x2-x1)\n",
    "    b = y1 - (m * x1)\n",
    "    # Ax + By + C\n",
    "    #1y - mx - b = 0\n",
    "    v = np.array([-m, 1, -b])\n",
    "    return v\n",
    "\n",
    "def intersection_two_points(A, B):\n",
    "    Av = vector_from_points(A['x1'], A['y1'], A['x2'], A['y2'])\n",
    "    Bv = vector_from_points(B['x1'], B['y1'], B['x2'], B['y2'])\n",
    "    cross = np.cross(Av, Bv)\n",
    "    cross /= cross[2]\n",
    "    return int(cross[0]), int(cross[1])\n",
    "\n",
    "A = {'x1':0, 'y1':4, 'x2':4, 'y2':0}\n",
    "B = {'x1':0, 'y1':0, 'x2':4, 'y2':4}\n",
    "intersection_two_points(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include horizontal and vertical line intersections only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersecting_points(lines):\n",
    "    horizontal_lines = [l for l in lines if 'horizontal' in l['orient']]\n",
    "    vertical_lines = [l for l in lines if 'vertical' in l['orient']]\n",
    "    intersecting_points = []\n",
    "    for hl in horizontal_lines:\n",
    "        hp = {'x1':hl['x1'], 'y1':hl['y1'], 'x2':hl['x2'], 'y2':hl['y2']}\n",
    "        for vl in vertical_lines:\n",
    "            vp = {'x1':vl['x1'], 'y1':vl['y1'], 'x2':vl['x2'], 'y2':vl['y2']}\n",
    "            intersection = intersection_two_points(hp, vp)\n",
    "            intersecting_points.append(intersection)\n",
    "    return intersecting_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting_points = find_intersecting_points(new_coords)\n",
    "intersecting_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot\n",
    "img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "for point in intersecting_points:\n",
    "    cv2.circle(img, point, 1, color=(255,0,0), thickness=5)\n",
    "    \n",
    "plot_img(img, fs=(18,18), title=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster points with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(intersecting_points)\n",
    "print(points.shape)\n",
    "def cluster_points(points, n_clusters):\n",
    "    points = np.float32(points)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    _, _, centers = cv2.kmeans(points, n_clusters, None, criteria, 10, cv2.KMEANS_PP_CENTERS)\n",
    "    return centers.astype(int)\n",
    "centers = cluster_points(points, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot\n",
    "img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "for c in centers:\n",
    "    cv2.circle(img, (c[0],c[1]), 1, color=(255,0,0), thickness=5)\n",
    "    \n",
    "plot_img(img, fs=(18,18), title=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment court\n",
    "\n",
    "* https://stackoverflow.com/questions/17241830/opencv-polylines-function-in-python-throws-exception/18817152#18817152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sorted = centers[centers[:,1].argsort()]\n",
    "\n",
    "# Top left and right\n",
    "top = y_sorted[:2]\n",
    "top = top[top[:,0].argsort()]\n",
    "top_left = top[0]\n",
    "top_right = top[1]\n",
    "\n",
    "# Bottom left and right\n",
    "bottom = y_sorted[2:]\n",
    "bottom = bottom[bottom[:,0].argsort()]\n",
    "bottom_left = bottom[0]\n",
    "bottom_right = bottom[1]\n",
    "\n",
    "ordered_points = [top_left,top_right,bottom_left,bottom_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "masked_img = cv2.fillPoly(img, np.array([centers.tolist()]), color=(255,255,255))\n",
    "plot_img(masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_cv2_img(img_fpath, colorspace=cv2.COLOR_BGR2RGB)\n",
    "img = cv2.polylines(img, np.array([centers.tolist()]), isClosed=1, color=(255,255,255), thickness=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
