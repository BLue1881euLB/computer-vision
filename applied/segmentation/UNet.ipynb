{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet\n",
    "\n",
    "* U-Net: Convolutional Networks for Biomedical Image Segmentation https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"/home/bfortuner/workplace/VisionQuest\")\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pascal VOC or Carvana?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                  stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    ]\n",
    "\n",
    "class UNet128(nn.Module):\n",
    "    def __init__(self, in_shape, num_classes):\n",
    "        super().__init__()\n",
    "        in_channels, height, width = in_shape\n",
    "\n",
    "        #128\n",
    "\n",
    "        self.down1 = nn.Sequential(\n",
    "            *make_conv_bn_relu(in_channels, 16, kernel_size=3, stride=1, padding=1 ),\n",
    "            *make_conv_bn_relu(16, 32, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #64\n",
    "\n",
    "        self.down2 = nn.Sequential(\n",
    "            *make_conv_bn_relu(32, 64,  kernel_size=3, stride=1, padding=1 ),\n",
    "            *make_conv_bn_relu(64, 128, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #32\n",
    "\n",
    "        self.down3 = nn.Sequential(\n",
    "            *make_conv_bn_relu(128, 256, kernel_size=3, stride=1, padding=1 ),\n",
    "            *make_conv_bn_relu(256, 512, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #16\n",
    "\n",
    "        self.down4 = nn.Sequential(\n",
    "            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n",
    "            *make_conv_bn_relu(512,512, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #8\n",
    "\n",
    "        self.same = nn.Sequential(\n",
    "            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "\n",
    "        #16\n",
    "        self.up4 = nn.Sequential(\n",
    "            *make_conv_bn_relu(1024,512, kernel_size=1, stride=1, padding=0 ),\n",
    "            *make_conv_bn_relu( 512,512, kernel_size=3, stride=1, padding=1 ),\n",
    "            #nn.Dropout(p=0.10),\n",
    "        )\n",
    "        #16\n",
    "\n",
    "        self.up3 = nn.Sequential(\n",
    "            *make_conv_bn_relu(1024,512, kernel_size=1, stride=1, padding=0 ),\n",
    "            *make_conv_bn_relu( 512,128, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "        #32\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            *make_conv_bn_relu(256,128, kernel_size=1, stride=1, padding=0 ),\n",
    "            *make_conv_bn_relu(128, 32, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "        #64\n",
    "\n",
    "        self.up1 = nn.Sequential(\n",
    "            *make_conv_bn_relu(64, 64, kernel_size=1, stride=1, padding=0 ),\n",
    "            *make_conv_bn_relu(64, 32, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "        \n",
    "        #128\n",
    "        self.classify = nn.Conv2d(32, num_classes, kernel_size=1, stride=1, padding=0 )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #128\n",
    "        down1 = self.down1(x)\n",
    "        out   = F.max_pool2d(down1, kernel_size=2, stride=2) #64\n",
    "\n",
    "        down2 = self.down2(out)\n",
    "        out   = F.max_pool2d(down2, kernel_size=2, stride=2) #32\n",
    "\n",
    "        down3 = self.down3(out)\n",
    "        out   = F.max_pool2d(down3, kernel_size=2, stride=2) #16\n",
    "\n",
    "        down4 = self.down4(out)\n",
    "        out   = F.max_pool2d(down4, kernel_size=2, stride=2) # 8\n",
    "\n",
    "        out   = self.same(out)\n",
    "\n",
    "        out   = F.upsample(out, scale_factor=2) #16\n",
    "        #print(out.size(), down4.size())\n",
    "        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n",
    "        #print(out.size(), down4.size())\n",
    "        out   = torch.cat([down4, out],1)\n",
    "        out   = self.up4(out)\n",
    "\n",
    "        out   = F.upsample(out, scale_factor=2) #32\n",
    "        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n",
    "        #print(out.size(), down3.size())\n",
    "        out   = torch.cat([down3, out],1)\n",
    "        out   = self.up3(out)\n",
    "\n",
    "        out   = F.upsample(out, scale_factor=2) #64\n",
    "        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n",
    "        out   = torch.cat([down2, out],1)\n",
    "        out   = self.up2(out)\n",
    "\n",
    "        out   = F.upsample(out, scale_factor=2) #128\n",
    "        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n",
    "        out   = torch.cat([down1, out],1)\n",
    "        out   = self.up1(out)\n",
    "        out   = self.classify(out)\n",
    "        out   = F.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNet128Pad(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_shape, num_classes):\n",
    "        super().__init__()\n",
    "        in_channels, height, width = in_shape\n",
    "\n",
    "        #128\n",
    "\n",
    "        self.down1 = nn.Sequential(\n",
    "            *make_conv_bn_relu(in_channels, 16, kernel_size=3, stride=1, padding=1 ),\n",
    "            *make_conv_bn_relu(16, 32, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #64\n",
    "\n",
    "        self.down2 = nn.Sequential(\n",
    "            *make_conv_bn_relu(32, 64,  kernel_size=3, stride=1, padding=1 ),\n",
    "            *make_conv_bn_relu(64, 128, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #32\n",
    "\n",
    "        self.down3 = nn.Sequential(\n",
    "            *make_conv_bn_relu(128, 256, kernel_size=3, stride=1, padding=1 ),\n",
    "            *make_conv_bn_relu(256, 512, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #16\n",
    "\n",
    "        self.down4 = nn.Sequential(\n",
    "            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n",
    "            *make_conv_bn_relu(512,512, kernel_size=1, stride=1, padding=0 ),\n",
    "        )\n",
    "        #8\n",
    "\n",
    "        self.same = nn.Sequential(\n",
    "            *make_conv_bn_relu(512,512, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "\n",
    "        #16\n",
    "        self.up4 = nn.Sequential(\n",
    "            *make_conv_bn_relu(1024,512, kernel_size=1, stride=1, padding=0 ),\n",
    "            *make_conv_bn_relu( 512,512, kernel_size=3, stride=1, padding=1 ),\n",
    "            #nn.Dropout(p=0.10),\n",
    "        )\n",
    "        #16\n",
    "\n",
    "        self.up3 = nn.Sequential(\n",
    "            *make_conv_bn_relu(1024,512, kernel_size=1, stride=1, padding=0 ),\n",
    "            *make_conv_bn_relu( 512,128, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "        #32\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            *make_conv_bn_relu(256,128, kernel_size=1, stride=1, padding=0 ),\n",
    "            *make_conv_bn_relu(128, 32, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "        #64\n",
    "\n",
    "        self.up1 = nn.Sequential(\n",
    "            *make_conv_bn_relu(64, 64, kernel_size=1, stride=1, padding=0 ),\n",
    "            *make_conv_bn_relu(64, 32, kernel_size=3, stride=1, padding=1 ),\n",
    "        )\n",
    "        #128\n",
    "\n",
    "        self.classify = nn.Conv2d(32, num_classes, kernel_size=1, stride=1, padding=0 )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #128\n",
    "        down1 = self.down1(x)\n",
    "        out   = F.max_pool2d(down1, kernel_size=2, stride=2) #64\n",
    "\n",
    "        down2 = self.down2(out)\n",
    "        out   = F.max_pool2d(down2, kernel_size=2, stride=2) #32\n",
    "\n",
    "        down3 = self.down3(out)\n",
    "        out   = F.max_pool2d(down3, kernel_size=2, stride=2) #16\n",
    "\n",
    "        down4 = self.down4(out)\n",
    "        out   = F.max_pool2d(down4, kernel_size=2, stride=2) # 8\n",
    "\n",
    "        out   = self.same(out)\n",
    "\n",
    "        out   = F.upsample(out, scale_factor=2) #16\n",
    "        #print(out.size(), down4.size())\n",
    "        out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n",
    "        #print(out.size(), down4.size())\n",
    "        out   = torch.cat([down4, out],1)\n",
    "        out   = self.up4(out)\n",
    "\n",
    "        out   = F.upsample(out, scale_factor=2) #32\n",
    "        out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n",
    "        #print(out.size(), down3.size())\n",
    "        out   = torch.cat([down3, out],1)\n",
    "        out   = self.up3(out)\n",
    "\n",
    "        out   = F.upsample(out, scale_factor=2) #64\n",
    "        out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n",
    "        out   = torch.cat([down2, out],1)\n",
    "        out   = self.up2(out)\n",
    "\n",
    "        out   = F.upsample(out, scale_factor=2) #128\n",
    "        #print(out.size())\n",
    "        #out   = torch.nn.ZeroPad2d((1,0,0,0))(out)\n",
    "        #print(out.size(), down1.size())\n",
    "        out   = torch.cat([down1, out],1)\n",
    "        out   = self.up1(out)\n",
    "        out   = self.classify(out)\n",
    "        out   = F.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = UNet128(in_shape=(3,128,128), num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* U-Net: Convolutional Networks for Biomedical Image Segmentation https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "116px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
